{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d520d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bad125",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/generate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a440d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": \"gemma3:latest\",\n",
    "    \"prompt\": \"A photo of a cat in a hat\",\n",
    "    \"negative_prompt\": \"A photo of a cat in a hat, blurry, out of focus\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390f9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url,json=data,stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf05ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as output.png\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    with open(\"output.png\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Image saved as output.png\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288e45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain-community langchain-ollama langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b229d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72419fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc_path = \"./\"\n",
    "model_name = \"gemma3:latest\"\n",
    "embedding_model = \"nomic-embed-text\"\n",
    "vectorstore_path = \"chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fff9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_pdf(doc_path):\n",
    "    loader = PyPDFLoader(doc_path)\n",
    "    data = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunk = text_splitter.split_documents(data)\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e624355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(chunk):\n",
    "    ollama.pull(embedding_model)\n",
    "    embeddings = OllamaEmbeddings(model=embedding_model)\n",
    "    vector_db = Chroma.from_documents(documents=chunk, embedding=embeddings, collection_name=vectorstore_path)\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf6d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = ingest_pdf(os.path.join(Doc_path, \"Test Analyst - Template 14.pdf\"))\n",
    "vectorstore = create_vector(chunk)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29fdf3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Test Analyst - Template 14.pdf', 'page_label': '1', 'creationdate': '', 'total_pages': 1, 'producer': 'Skia/PDF m102 Google Docs Renderer', 'page': 0, 'creator': 'PyPDF', 'title': 'Test Analyst - Template 14'}, page_content='Growthsi, San Francisco, CA 2013 – 2015Test Analyst\\n● Implementedpredictive analytics and regression analysistechniques for quantifying durability which led toa 12% increase in the product’s overall durability.● Created effective UAT plans & scripts meeting the acceptance criteria that resulted in a 10% saving intesting time.● Developed data comparison-speciﬁc MS Excel macros and reduced the test execution time by 45%.\\nResume Worded Exciting Company, San Francisco, CA 2011 – 2013Junior Test Analyst● Collaborated in the automation of the test-case design along with team members that saved an overall of55% of test design time.● Carried out an automation sanity test that preceded every deployment dropping the testing time by 40%.● Performed multiple physical testing methods simultaneously which increased eﬃciency by 15%.\\nEDUCATION'),\n",
       " Document(metadata={'creationdate': '', 'page_label': '1', 'source': './Test Analyst - Template 14.pdf', 'total_pages': 1, 'title': 'Test Analyst - Template 14', 'page': 0, 'producer': 'Skia/PDF m102 Google Docs Renderer', 'creator': 'PyPDF'}, page_content='Growthsi, San Francisco, CA 2013 – 2015Test Analyst\\n● Implementedpredictive analytics and regression analysistechniques for quantifying durability which led toa 12% increase in the product’s overall durability.● Created effective UAT plans & scripts meeting the acceptance criteria that resulted in a 10% saving intesting time.● Developed data comparison-speciﬁc MS Excel macros and reduced the test execution time by 45%.\\nResume Worded Exciting Company, San Francisco, CA 2011 – 2013Junior Test Analyst● Collaborated in the automation of the test-case design along with team members that saved an overall of55% of test design time.● Carried out an automation sanity test that preceded every deployment dropping the testing time by 40%.● Performed multiple physical testing methods simultaneously which increased eﬃciency by 15%.\\nEDUCATION'),\n",
       " Document(metadata={'title': 'Test Analyst - Template 14', 'creationdate': '', 'creator': 'PyPDF', 'total_pages': 1, 'page': 0, 'source': './Test Analyst - Template 14.pdf', 'producer': 'Skia/PDF m102 Google Docs Renderer', 'page_label': '1'}, page_content='EDUCATION\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Resume Worded University, New York, NYBachelor of Engineering —\\xa0Systems Design\\nSKILLS\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Technical Skills: Jira, Scrum, Test Automation Frameworks, Regression Testing, Selenium, JavaLanguages: English (Native), German (Fluent), French(Conversational)')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"what is experience in the field of data science?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3b9a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "You are an AI language model assistant. Your task is to generate five\n",
    "different versions of the given user question to retrieve relevant documents from\n",
    "a vector database. By generating multiple perspectives on the user question, your\n",
    "goal is to help the user overcome some of the limitations of the distance-based\n",
    "similarity search. Provide these alternative questions separated by newlines.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c21f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.as_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473adfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(vectorstore,llm):\n",
    "    Query_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"Given the context: {context}, answer the question: {question}\",\n",
    "    )\n",
    "\n",
    "    retriever = MultiQueryRetriever.from_llm(\n",
    "        vectorstore.as_retriever(), llm=llm,prompt=Query_prompt,\n",
    "        output_parser=StrOutputParser(),  # type: ignore\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(retriever,llm):\n",
    "    template = \"\"\"Answer the question based on the context provided. If the answer is not in the context, say \"I don't know\".\n",
    "    Context: {context}\"\n",
    "    \"\"\"\n",
    "    context = \"You are an AI language model assistant. Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. Provide these alternative questions separated by newlines.\"\n",
    "    return template.format(context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
